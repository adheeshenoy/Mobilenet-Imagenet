{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vNRbdMk0Ok5F"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 03:36:08.876440: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import tarfile \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from math import log2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p0ic8eJSAZ5Y"
   },
   "source": [
    "# Extract and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9m5-_JLTO2Ua"
   },
   "outputs": [],
   "source": [
    "def extract_data(tarfile_path = './dataset.tar'):\n",
    "  with tarfile.TarFile(tarfile_path) as f:\n",
    "    f.extractall()\n",
    "\n",
    "extract_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oVeYkApjV6hS",
    "outputId": "8eadb738-90c0-4476-a7e4-43d0d1d6ac1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 files belonging to 1000 classes.\n",
      "Found 50000 files belonging to 1000 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_ds = keras.utils.image_dataset_from_directory(\n",
    "    './Dataset/train',\n",
    "    label_mode='int',\n",
    "    batch_size=batch_size,\n",
    "    image_size=(224, 224),\n",
    ")\n",
    "\n",
    "val_ds = keras.utils.image_dataset_from_directory(\n",
    "    './Dataset/val',\n",
    "    label_mode='int',\n",
    "    batch_size=batch_size,\n",
    "    image_size=(224, 224),\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQanVj5vAml-"
   },
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDhAxNpiBvod"
   },
   "source": [
    "## Get Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Nj47VfSHO2Rx"
   },
   "outputs": [],
   "source": [
    "mobile_net_feature_extractor = keras.applications.mobilenet_v2.MobileNetV2(\n",
    "    alpha=1,\n",
    "    include_top=False, \n",
    "    weights='imagenet', \n",
    "    input_shape = (224,224,3), \n",
    "    pooling='avg'\n",
    "    )\n",
    "for layer in mobile_net_feature_extractor.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenetv2_1.00_224\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_12 (InputLayer)          [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)                 (None, 112, 112, 32  864         ['input_12[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalization)  (None, 112, 112, 32  128         ['Conv1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)              (None, 112, 112, 32  0           ['bn_Conv1[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (Depth  (None, 112, 112, 32  288        ['Conv1_relu[0][0]']             \n",
      " wiseConv2D)                    )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN (Ba  (None, 112, 112, 32  128        ['expanded_conv_depthwise[0][0]']\n",
      " tchNormalization)              )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_relu (  (None, 112, 112, 32  0          ['expanded_conv_depthwise_BN[0][0\n",
      " ReLU)                          )                                ]']                              \n",
      "                                                                                                  \n",
      " expanded_conv_project (Conv2D)  (None, 112, 112, 16  512        ['expanded_conv_depthwise_relu[0]\n",
      "                                )                                [0]']                            \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (Batc  (None, 112, 112, 16  64         ['expanded_conv_project[0][0]']  \n",
      " hNormalization)                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)        (None, 112, 112, 96  1536        ['expanded_conv_project_BN[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNormal  (None, 112, 112, 96  384        ['block_1_expand[0][0]']         \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)     (None, 112, 112, 96  0           ['block_1_expand_BN[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D)    (None, 113, 113, 96  0           ['block_1_expand_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_depthwise (DepthwiseCo  (None, 56, 56, 96)  864         ['block_1_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (BatchNor  (None, 56, 56, 96)  384         ['block_1_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (ReLU)  (None, 56, 56, 96)   0           ['block_1_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)       (None, 56, 56, 24)   2304        ['block_1_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_1_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_1_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_2_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_2_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_2_depthwise (DepthwiseCo  (None, 56, 56, 144)  1296       ['block_2_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (BatchNor  (None, 56, 56, 144)  576        ['block_2_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (ReLU)  (None, 56, 56, 144)  0           ['block_2_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)       (None, 56, 56, 24)   3456        ['block_2_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_2_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_add (Add)              (None, 56, 56, 24)   0           ['block_1_project_BN[0][0]',     \n",
      "                                                                  'block_2_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_3_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_2_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_3_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_3_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_3_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_3_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_3_pad (ZeroPadding2D)    (None, 57, 57, 144)  0           ['block_3_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_3_depthwise (DepthwiseCo  (None, 28, 28, 144)  1296       ['block_3_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_3_depthwise_BN (BatchNor  (None, 28, 28, 144)  576        ['block_3_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_3_depthwise_relu (ReLU)  (None, 28, 28, 144)  0           ['block_3_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_3_project (Conv2D)       (None, 28, 28, 32)   4608        ['block_3_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_3_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_3_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_3_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_4_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_4_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_4_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_4_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_4_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_4_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_4_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_4_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_4_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_4_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_4_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_4_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_4_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_4_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_add (Add)              (None, 28, 28, 32)   0           ['block_3_project_BN[0][0]',     \n",
      "                                                                  'block_4_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_5_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_4_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_5_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_5_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_5_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_5_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_5_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_5_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_5_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_5_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_5_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_5_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_5_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_5_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_5_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_5_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_5_add (Add)              (None, 28, 28, 32)   0           ['block_4_add[0][0]',            \n",
      "                                                                  'block_5_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_6_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_5_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_6_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_6_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_6_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_6_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_6_pad (ZeroPadding2D)    (None, 29, 29, 192)  0           ['block_6_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_6_depthwise (DepthwiseCo  (None, 14, 14, 192)  1728       ['block_6_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_6_depthwise_BN (BatchNor  (None, 14, 14, 192)  768        ['block_6_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_6_depthwise_relu (ReLU)  (None, 14, 14, 192)  0           ['block_6_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_6_project (Conv2D)       (None, 14, 14, 64)   12288       ['block_6_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_6_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_6_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_6_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_7_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_7_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_7_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_7_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_7_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_7_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_7_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_7_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_7_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_7_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_7_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_7_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_7_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_7_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_add (Add)              (None, 14, 14, 64)   0           ['block_6_project_BN[0][0]',     \n",
      "                                                                  'block_7_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_8_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_7_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_8_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_8_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_8_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_8_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_8_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_8_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_8_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_8_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_8_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_8_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_8_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_8_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_8_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_8_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_8_add (Add)              (None, 14, 14, 64)   0           ['block_7_add[0][0]',            \n",
      "                                                                  'block_8_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_9_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_8_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_9_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_9_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_9_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_9_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_9_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_9_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_9_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_9_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_9_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_9_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_9_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_9_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_9_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_9_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_9_add (Add)              (None, 14, 14, 64)   0           ['block_8_add[0][0]',            \n",
      "                                                                  'block_9_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_expand (Conv2D)       (None, 14, 14, 384)  24576       ['block_9_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_10_expand_BN (BatchNorma  (None, 14, 14, 384)  1536       ['block_10_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_10_expand_relu (ReLU)    (None, 14, 14, 384)  0           ['block_10_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_depthwise (DepthwiseC  (None, 14, 14, 384)  3456       ['block_10_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_10_depthwise_BN (BatchNo  (None, 14, 14, 384)  1536       ['block_10_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0          ['block_10_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_10_project (Conv2D)      (None, 14, 14, 96)   36864       ['block_10_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_10_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_10_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_10_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_11_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_11_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_11_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_11_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_11_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_11_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_11_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_11_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_11_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_11_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_11_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_11_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_11_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_add (Add)             (None, 14, 14, 96)   0           ['block_10_project_BN[0][0]',    \n",
      "                                                                  'block_11_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_12_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_11_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_12_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_12_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_12_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_12_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_12_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_12_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_12_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_12_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_12_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_12_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_12_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_12_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_12_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_12_add (Add)             (None, 14, 14, 96)   0           ['block_11_add[0][0]',           \n",
      "                                                                  'block_12_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_13_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_12_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_13_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_13_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_13_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_13_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_13_pad (ZeroPadding2D)   (None, 15, 15, 576)  0           ['block_13_expand_relu[0][0]']   \n",
      "                                                                                                  \n",
      " block_13_depthwise (DepthwiseC  (None, 7, 7, 576)   5184        ['block_13_pad[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_13_depthwise_BN (BatchNo  (None, 7, 7, 576)   2304        ['block_13_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)   0           ['block_13_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_13_project (Conv2D)      (None, 7, 7, 160)    92160       ['block_13_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_13_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_13_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_13_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_14_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_14_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_14_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_14_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_14_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_14_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_14_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_14_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_14_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_14_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_14_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_14_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_14_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_add (Add)             (None, 7, 7, 160)    0           ['block_13_project_BN[0][0]',    \n",
      "                                                                  'block_14_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_15_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_14_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_15_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_15_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_15_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_15_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_15_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_15_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_15_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_15_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_15_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_15_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_15_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_15_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_15_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_15_add (Add)             (None, 7, 7, 160)    0           ['block_14_add[0][0]',           \n",
      "                                                                  'block_15_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_16_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_15_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_16_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_16_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_16_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_16_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_16_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_16_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_16_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_16_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_16_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_16_project (Conv2D)      (None, 7, 7, 320)    307200      ['block_16_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_16_project_BN (BatchNorm  (None, 7, 7, 320)   1280        ['block_16_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)                (None, 7, 7, 1280)   409600      ['block_16_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)  5120        ['Conv_1[0][0]']                 \n",
      "                                                                                                  \n",
      " out_relu (ReLU)                (None, 7, 7, 1280)   0           ['Conv_1_bn[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling2d_9 (Gl  (None, 1280)        0           ['out_relu[0][0]']               \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,257,984\n",
      "Trainable params: 0\n",
      "Non-trainable params: 2,257,984\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mobile_net_feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DZx07DUMBzG6"
   },
   "source": [
    "## Helper Functions to create models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "kz9lNgpiO2Lu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " tf.math.truediv_4 (TFOpLamb  (None, 224, 224, 3)      0         \n",
      " da)                                                             \n",
      "                                                                 \n",
      " tf.math.subtract_4 (TFOpLam  (None, 224, 224, 3)      0         \n",
      " bda)                                                            \n",
      "                                                                 \n",
      " model_5 (Functional)        (None, 7, 7, 320)         1843264   \n",
      "                                                                 \n",
      " global_average_pooling2d_6   (None, 320)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1000)              321000    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,164,264\n",
      "Trainable params: 321,000\n",
      "Non-trainable params: 1,843,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_baseline_model(feature_extractor, classes = 1000, image_size = 224):\n",
    "    inp = keras.Input(shape = (image_size, image_size,3))\n",
    "    x = keras.applications.mobilenet_v2.preprocess_input(inp)\n",
    "    x = feature_extractor(x)\n",
    "    out = keras.layers.Dense(classes, activation = 'softmax')(x)\n",
    "\n",
    "    return keras.models.Model(inputs=[inp], outputs= [out])\n",
    "\n",
    "def create_mec_model(feature_extractor, classes = 1000, image_size = 224):\n",
    "    '''1280 * 32 + 32'''\n",
    "    inp = keras.Input(shape = (image_size, image_size,3))\n",
    "    x = keras.applications.mobilenet_v2.preprocess_input(inp)\n",
    "    x = feature_extractor(x)\n",
    "    x = keras.layers.Dense(32, activation = 'relu')(x)\n",
    "    out = keras.layers.Dense(classes, activation = 'softmax')(x)\n",
    "    return keras.models.Model(inputs=[inp], outputs= [out]) \n",
    "\n",
    "def create_information_capacity_model(feature_extractor, classes = 1000, image_size = 224):\n",
    "    '''1280 * 77 + 77'''\n",
    "    inp = keras.Input(shape = (image_size, image_size,3))\n",
    "    x = keras.applications.mobilenet_v2.preprocess_input(inp)\n",
    "    x = feature_extractor(x)\n",
    "    x = keras.layers.Dense(77, activation = 'relu')(x)\n",
    "    out = keras.layers.Dense(classes, activation = 'softmax')(x)\n",
    "    return keras.models.Model(inputs=[inp], outputs= [out]) \n",
    "\n",
    "def increased_compression_model(feature_extractor, classes = 1000, image_size = 224):\n",
    "    feature_extractor = keras.models.Model(feature_extractor.input, feature_extractor.layers[-5].output)\n",
    "    \n",
    "    inp = keras.Input(shape = (image_size, image_size,3))\n",
    "    x = keras.applications.mobilenet_v2.preprocess_input(inp)\n",
    "    x = feature_extractor(x)\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    out = keras.layers.Dense(classes, activation = 'softmax')(x)\n",
    "    return keras.models.Model(inputs=[inp], outputs= [out]) \n",
    "\n",
    "model = increased_compression_model(mobile_net_feature_extractor)\n",
    "model.summary()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lRdsWhRzCGzw"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "8aKxPaoSF_Hd"
   },
   "outputs": [],
   "source": [
    "model_name = 'baseline_overfit'\n",
    "os.mkdir(model_name)\n",
    "epochs = 1000\n",
    "overfit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "S9JGuRdeVdpb"
   },
   "outputs": [],
   "source": [
    "model = create_baseline_model(mobile_net_feature_extractor)\n",
    "# model = create_mec_model(mobile_net_feature_extractor)\n",
    "# model = create_information_capacity_model(mobile_net_feature_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "GOL0bg60EIZJ"
   },
   "outputs": [],
   "source": [
    "if overfit:\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='loss', patience= 10, verbose = 1),\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath = f'./{model_name}/{model_name}.h5', monitor = 'loss', save_best_only = True, verbose = 1),\n",
    "        tf.keras.callbacks.LearningRateScheduler(keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.045, decay_steps=1, decay_rate=0.98))\n",
    "        ]\n",
    "else:\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience= 10, verbose = 1),\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath = f'./{model_name}/{model_name}.h5', monitor = 'val_loss', save_best_only = True, verbose = 1),\n",
    "        tf.keras.callbacks.LearningRateScheduler(keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.045, decay_steps=1, decay_rate=0.98))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w6iaMXfeRDj4",
    "outputId": "035fe0a1-6b07-4cb2-c176-37b3fce68efe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 109.8463 - accuracy: 0.6168\n",
      "Epoch 1: loss improved from inf to 109.83484, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 50s 61ms/step - loss: 109.8348 - accuracy: 0.6169 - val_loss: 187.5209 - val_accuracy: 0.5469 - lr: 0.0450\n",
      "Epoch 2/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 74.3713 - accuracy: 0.7304\n",
      "Epoch 2: loss improved from 109.83484 to 74.37264, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 74.3726 - accuracy: 0.7304 - val_loss: 200.7561 - val_accuracy: 0.5636 - lr: 0.0441\n",
      "Epoch 3/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 52.7193 - accuracy: 0.7895\n",
      "Epoch 3: loss improved from 74.37264 to 52.71735, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 52.7174 - accuracy: 0.7895 - val_loss: 211.4366 - val_accuracy: 0.5697 - lr: 0.0432\n",
      "Epoch 4/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 38.6038 - accuracy: 0.8278\n",
      "Epoch 4: loss improved from 52.71735 to 38.61247, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 38.6125 - accuracy: 0.8277 - val_loss: 222.7035 - val_accuracy: 0.5741 - lr: 0.0424\n",
      "Epoch 5/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 29.0028 - accuracy: 0.8562\n",
      "Epoch 5: loss improved from 38.61247 to 28.99905, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 28.9991 - accuracy: 0.8562 - val_loss: 225.5862 - val_accuracy: 0.5815 - lr: 0.0415\n",
      "Epoch 6/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 22.1314 - accuracy: 0.8794\n",
      "Epoch 6: loss improved from 28.99905 to 22.13308, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 22.1331 - accuracy: 0.8794 - val_loss: 230.4421 - val_accuracy: 0.5867 - lr: 0.0407\n",
      "Epoch 7/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 16.6541 - accuracy: 0.8998\n",
      "Epoch 7: loss improved from 22.13308 to 16.66050, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 16.6605 - accuracy: 0.8997 - val_loss: 237.8668 - val_accuracy: 0.5854 - lr: 0.0399\n",
      "Epoch 8/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 13.3113 - accuracy: 0.9138\n",
      "Epoch 8: loss improved from 16.66050 to 13.31112, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 13.3111 - accuracy: 0.9138 - val_loss: 237.0109 - val_accuracy: 0.5915 - lr: 0.0391\n",
      "Epoch 9/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 10.3633 - accuracy: 0.9281\n",
      "Epoch 9: loss improved from 13.31112 to 10.36001, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 10.3600 - accuracy: 0.9281 - val_loss: 236.2189 - val_accuracy: 0.5945 - lr: 0.0383\n",
      "Epoch 10/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 8.4556 - accuracy: 0.9379\n",
      "Epoch 10: loss improved from 10.36001 to 8.45340, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 8.4534 - accuracy: 0.9379 - val_loss: 235.9334 - val_accuracy: 0.5945 - lr: 0.0375\n",
      "Epoch 11/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 6.8586 - accuracy: 0.9459\n",
      "Epoch 11: loss improved from 8.45340 to 6.85636, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 6.8564 - accuracy: 0.9459 - val_loss: 237.4773 - val_accuracy: 0.5989 - lr: 0.0368\n",
      "Epoch 12/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 5.4897 - accuracy: 0.9537\n",
      "Epoch 12: loss improved from 6.85636 to 5.48820, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 5.4882 - accuracy: 0.9537 - val_loss: 240.2290 - val_accuracy: 0.6006 - lr: 0.0360\n",
      "Epoch 13/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 4.6352 - accuracy: 0.9591\n",
      "Epoch 13: loss improved from 5.48820 to 4.63398, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 4.6340 - accuracy: 0.9591 - val_loss: 235.1933 - val_accuracy: 0.6045 - lr: 0.0353\n",
      "Epoch 14/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 3.8266 - accuracy: 0.9646\n",
      "Epoch 14: loss improved from 4.63398 to 3.82797, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 3.8280 - accuracy: 0.9646 - val_loss: 237.3543 - val_accuracy: 0.6051 - lr: 0.0346\n",
      "Epoch 15/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 3.0520 - accuracy: 0.9692\n",
      "Epoch 15: loss improved from 3.82797 to 3.05098, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 3.0510 - accuracy: 0.9692 - val_loss: 237.0463 - val_accuracy: 0.6066 - lr: 0.0339\n",
      "Epoch 16/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 2.5423 - accuracy: 0.9739\n",
      "Epoch 16: loss improved from 3.05098 to 2.54149, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 2.5415 - accuracy: 0.9739 - val_loss: 236.7868 - val_accuracy: 0.6062 - lr: 0.0332\n",
      "Epoch 17/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 2.1309 - accuracy: 0.9772\n",
      "Epoch 17: loss improved from 2.54149 to 2.13022, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 2.1302 - accuracy: 0.9772 - val_loss: 236.3611 - val_accuracy: 0.6085 - lr: 0.0326\n",
      "Epoch 18/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.7474 - accuracy: 0.9808\n",
      "Epoch 18: loss improved from 2.13022 to 1.74682, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 1.7468 - accuracy: 0.9808 - val_loss: 237.9360 - val_accuracy: 0.6070 - lr: 0.0319\n",
      "Epoch 19/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.4774 - accuracy: 0.9829\n",
      "Epoch 19: loss improved from 1.74682 to 1.47695, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 1.4770 - accuracy: 0.9829 - val_loss: 235.9691 - val_accuracy: 0.6086 - lr: 0.0313\n",
      "Epoch 20/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.2677 - accuracy: 0.9851\n",
      "Epoch 20: loss improved from 1.47695 to 1.26908, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 1.2691 - accuracy: 0.9851 - val_loss: 234.3630 - val_accuracy: 0.6099 - lr: 0.0307\n",
      "Epoch 21/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 1.1325 - accuracy: 0.9866\n",
      "Epoch 21: loss improved from 1.26908 to 1.13272, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 1.1327 - accuracy: 0.9866 - val_loss: 235.7431 - val_accuracy: 0.6091 - lr: 0.0300\n",
      "Epoch 22/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.9089 - accuracy: 0.9886\n",
      "Epoch 22: loss improved from 1.13272 to 0.90864, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.9086 - accuracy: 0.9886 - val_loss: 234.2731 - val_accuracy: 0.6095 - lr: 0.0294\n",
      "Epoch 23/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.7465 - accuracy: 0.9904\n",
      "Epoch 23: loss improved from 0.90864 to 0.74625, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.7462 - accuracy: 0.9904 - val_loss: 232.1153 - val_accuracy: 0.6127 - lr: 0.0289\n",
      "Epoch 24/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.6187 - accuracy: 0.9915\n",
      "Epoch 24: loss improved from 0.74625 to 0.61877, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.6188 - accuracy: 0.9915 - val_loss: 232.6107 - val_accuracy: 0.6113 - lr: 0.0283\n",
      "Epoch 25/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.5319 - accuracy: 0.9931\n",
      "Epoch 25: loss improved from 0.61877 to 0.53211, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.5321 - accuracy: 0.9931 - val_loss: 233.0982 - val_accuracy: 0.6115 - lr: 0.0277\n",
      "Epoch 26/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.5057 - accuracy: 0.9931\n",
      "Epoch 26: loss improved from 0.53211 to 0.50559, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.5056 - accuracy: 0.9931 - val_loss: 231.5985 - val_accuracy: 0.6117 - lr: 0.0272\n",
      "Epoch 27/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.4413 - accuracy: 0.9941\n",
      "Epoch 27: loss improved from 0.50559 to 0.44115, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.4412 - accuracy: 0.9941 - val_loss: 230.5389 - val_accuracy: 0.6136 - lr: 0.0266\n",
      "Epoch 28/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3642 - accuracy: 0.9952\n",
      "Epoch 28: loss improved from 0.44115 to 0.36406, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.3641 - accuracy: 0.9952 - val_loss: 229.7237 - val_accuracy: 0.6147 - lr: 0.0261\n",
      "Epoch 29/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.3381 - accuracy: 0.9954\n",
      "Epoch 29: loss improved from 0.36406 to 0.33799, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.3380 - accuracy: 0.9954 - val_loss: 229.2353 - val_accuracy: 0.6152 - lr: 0.0256\n",
      "Epoch 30/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.2833 - accuracy: 0.9964\n",
      "Epoch 30: loss improved from 0.33799 to 0.28323, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.2832 - accuracy: 0.9964 - val_loss: 228.0179 - val_accuracy: 0.6155 - lr: 0.0250\n",
      "Epoch 31/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.2509 - accuracy: 0.9971\n",
      "Epoch 31: loss improved from 0.28323 to 0.25082, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.2508 - accuracy: 0.9971 - val_loss: 227.5004 - val_accuracy: 0.6170 - lr: 0.0245\n",
      "Epoch 32/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.2205 - accuracy: 0.9978\n",
      "Epoch 32: loss improved from 0.25082 to 0.22044, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.2204 - accuracy: 0.9978 - val_loss: 227.1547 - val_accuracy: 0.6179 - lr: 0.0241\n",
      "Epoch 33/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.1680 - accuracy: 0.9981\n",
      "Epoch 33: loss improved from 0.22044 to 0.16798, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.1680 - accuracy: 0.9981 - val_loss: 227.2826 - val_accuracy: 0.6180 - lr: 0.0236\n",
      "Epoch 34/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.1730 - accuracy: 0.9982\n",
      "Epoch 34: loss did not improve from 0.16798\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.1729 - accuracy: 0.9982 - val_loss: 227.2768 - val_accuracy: 0.6178 - lr: 0.0231\n",
      "Epoch 35/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.1725 - accuracy: 0.9983\n",
      "Epoch 35: loss did not improve from 0.16798\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.1725 - accuracy: 0.9983 - val_loss: 226.9541 - val_accuracy: 0.6180 - lr: 0.0226\n",
      "Epoch 36/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.1507 - accuracy: 0.9987\n",
      "Epoch 36: loss improved from 0.16798 to 0.15063, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.1506 - accuracy: 0.9987 - val_loss: 226.9879 - val_accuracy: 0.6185 - lr: 0.0222\n",
      "Epoch 37/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.1497 - accuracy: 0.9987\n",
      "Epoch 37: loss improved from 0.15063 to 0.14967, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.1497 - accuracy: 0.9987 - val_loss: 227.0006 - val_accuracy: 0.6177 - lr: 0.0217\n",
      "Epoch 38/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.1345 - accuracy: 0.9990\n",
      "Epoch 38: loss improved from 0.14967 to 0.13449, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.1345 - accuracy: 0.9991 - val_loss: 226.4660 - val_accuracy: 0.6184 - lr: 0.0213\n",
      "Epoch 39/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.1384 - accuracy: 0.9991\n",
      "Epoch 39: loss did not improve from 0.13449\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.1384 - accuracy: 0.9991 - val_loss: 226.0723 - val_accuracy: 0.6185 - lr: 0.0209\n",
      "Epoch 40/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.1337 - accuracy: 0.9991\n",
      "Epoch 40: loss improved from 0.13449 to 0.13367, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.1337 - accuracy: 0.9991 - val_loss: 226.3338 - val_accuracy: 0.6182 - lr: 0.0205\n",
      "Epoch 41/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.1286 - accuracy: 0.9991\n",
      "Epoch 41: loss improved from 0.13367 to 0.12853, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.1285 - accuracy: 0.9991 - val_loss: 225.9942 - val_accuracy: 0.6185 - lr: 0.0201\n",
      "Epoch 42/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.1312 - accuracy: 0.9992\n",
      "Epoch 42: loss did not improve from 0.12853\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.1311 - accuracy: 0.9992 - val_loss: 225.6339 - val_accuracy: 0.6190 - lr: 0.0197\n",
      "Epoch 43/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.1261 - accuracy: 0.9992\n",
      "Epoch 43: loss improved from 0.12853 to 0.12606, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.1261 - accuracy: 0.9992 - val_loss: 225.6827 - val_accuracy: 0.6190 - lr: 0.0193\n",
      "Epoch 44/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.1266 - accuracy: 0.9992\n",
      "Epoch 44: loss did not improve from 0.12606\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.1265 - accuracy: 0.9992 - val_loss: 225.7835 - val_accuracy: 0.6190 - lr: 0.0189\n",
      "Epoch 45/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.1255 - accuracy: 0.9992\n",
      "Epoch 45: loss improved from 0.12606 to 0.12543, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.1254 - accuracy: 0.9992 - val_loss: 225.7292 - val_accuracy: 0.6192 - lr: 0.0185\n",
      "Epoch 46/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.1264 - accuracy: 0.9991\n",
      "Epoch 46: loss did not improve from 0.12543\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.1264 - accuracy: 0.9991 - val_loss: 225.8348 - val_accuracy: 0.6193 - lr: 0.0181\n",
      "Epoch 47/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.1299 - accuracy: 0.9992\n",
      "Epoch 47: loss did not improve from 0.12543\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.1298 - accuracy: 0.9992 - val_loss: 225.6328 - val_accuracy: 0.6200 - lr: 0.0178\n",
      "Epoch 48/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.1253 - accuracy: 0.9992\n",
      "Epoch 48: loss improved from 0.12543 to 0.12521, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.1252 - accuracy: 0.9992 - val_loss: 225.5681 - val_accuracy: 0.6200 - lr: 0.0174\n",
      "Epoch 49/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.1289 - accuracy: 0.9992\n",
      "Epoch 49: loss did not improve from 0.12521\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.1289 - accuracy: 0.9992 - val_loss: 225.6302 - val_accuracy: 0.6199 - lr: 0.0171\n",
      "Epoch 50/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.1242 - accuracy: 0.9993\n",
      "Epoch 50: loss improved from 0.12521 to 0.12416, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.1242 - accuracy: 0.9993 - val_loss: 225.6461 - val_accuracy: 0.6197 - lr: 0.0167\n",
      "Epoch 51/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.1148 - accuracy: 0.9993\n",
      "Epoch 51: loss improved from 0.12416 to 0.11473, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.1147 - accuracy: 0.9993 - val_loss: 225.7955 - val_accuracy: 0.6196 - lr: 0.0164\n",
      "Epoch 52/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.1216 - accuracy: 0.9992\n",
      "Epoch 52: loss did not improve from 0.11473\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.1216 - accuracy: 0.9992 - val_loss: 225.7394 - val_accuracy: 0.6194 - lr: 0.0161\n",
      "Epoch 53/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.1195 - accuracy: 0.9992\n",
      "Epoch 53: loss did not improve from 0.11473\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.1195 - accuracy: 0.9992 - val_loss: 225.5424 - val_accuracy: 0.6199 - lr: 0.0157\n",
      "Epoch 54/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.1155 - accuracy: 0.9992\n",
      "Epoch 54: loss did not improve from 0.11473\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.1154 - accuracy: 0.9992 - val_loss: 225.6226 - val_accuracy: 0.6196 - lr: 0.0154\n",
      "Epoch 55/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.1065 - accuracy: 0.9993\n",
      "Epoch 55: loss improved from 0.11473 to 0.10643, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.1064 - accuracy: 0.9993 - val_loss: 225.6057 - val_accuracy: 0.6197 - lr: 0.0151\n",
      "Epoch 56/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.1101 - accuracy: 0.9992\n",
      "Epoch 56: loss did not improve from 0.10643\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.1101 - accuracy: 0.9992 - val_loss: 225.5923 - val_accuracy: 0.6197 - lr: 0.0148\n",
      "Epoch 57/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.1090 - accuracy: 0.9993\n",
      "Epoch 57: loss did not improve from 0.10643\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.1089 - accuracy: 0.9993 - val_loss: 225.6104 - val_accuracy: 0.6196 - lr: 0.0145\n",
      "Epoch 58/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.1112 - accuracy: 0.9993\n",
      "Epoch 58: loss did not improve from 0.10643\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.1111 - accuracy: 0.9993 - val_loss: 225.6053 - val_accuracy: 0.6194 - lr: 0.0142\n",
      "Epoch 59/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.1095 - accuracy: 0.9993\n",
      "Epoch 59: loss did not improve from 0.10643\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.1095 - accuracy: 0.9993 - val_loss: 225.6166 - val_accuracy: 0.6195 - lr: 0.0139\n",
      "Epoch 60/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.1059 - accuracy: 0.9993\n",
      "Epoch 60: loss improved from 0.10643 to 0.10588, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.1059 - accuracy: 0.9993 - val_loss: 225.5578 - val_accuracy: 0.6196 - lr: 0.0137\n",
      "Epoch 61/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.0999 - accuracy: 0.9993\n",
      "Epoch 61: loss improved from 0.10588 to 0.09988, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.0999 - accuracy: 0.9993 - val_loss: 225.5782 - val_accuracy: 0.6196 - lr: 0.0134\n",
      "Epoch 62/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.1010 - accuracy: 0.9993\n",
      "Epoch 62: loss did not improve from 0.09988\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.1010 - accuracy: 0.9993 - val_loss: 225.5889 - val_accuracy: 0.6195 - lr: 0.0131\n",
      "Epoch 63/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.0889 - accuracy: 0.9994\n",
      "Epoch 63: loss improved from 0.09988 to 0.08891, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.0889 - accuracy: 0.9994 - val_loss: 225.6432 - val_accuracy: 0.6195 - lr: 0.0129\n",
      "Epoch 64/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.0978 - accuracy: 0.9993\n",
      "Epoch 64: loss did not improve from 0.08891\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.0978 - accuracy: 0.9993 - val_loss: 225.5717 - val_accuracy: 0.6195 - lr: 0.0126\n",
      "Epoch 65/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.0927 - accuracy: 0.9993\n",
      "Epoch 65: loss did not improve from 0.08891\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.0926 - accuracy: 0.9993 - val_loss: 225.5555 - val_accuracy: 0.6195 - lr: 0.0124\n",
      "Epoch 66/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.0946 - accuracy: 0.9993\n",
      "Epoch 66: loss did not improve from 0.08891\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.0946 - accuracy: 0.9993 - val_loss: 225.4832 - val_accuracy: 0.6197 - lr: 0.0121\n",
      "Epoch 67/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.0878 - accuracy: 0.9993\n",
      "Epoch 67: loss improved from 0.08891 to 0.08781, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.0878 - accuracy: 0.9993 - val_loss: 225.4985 - val_accuracy: 0.6196 - lr: 0.0119\n",
      "Epoch 68/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.0908 - accuracy: 0.9993\n",
      "Epoch 68: loss did not improve from 0.08781\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.0908 - accuracy: 0.9993 - val_loss: 225.4800 - val_accuracy: 0.6195 - lr: 0.0116\n",
      "Epoch 69/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.0849 - accuracy: 0.9993\n",
      "Epoch 69: loss improved from 0.08781 to 0.08484, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.0848 - accuracy: 0.9993 - val_loss: 225.5051 - val_accuracy: 0.6194 - lr: 0.0114\n",
      "Epoch 70/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.0874 - accuracy: 0.9993\n",
      "Epoch 70: loss did not improve from 0.08484\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.0874 - accuracy: 0.9993 - val_loss: 225.5246 - val_accuracy: 0.6193 - lr: 0.0112\n",
      "Epoch 71/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.0766 - accuracy: 0.9993\n",
      "Epoch 71: loss improved from 0.08484 to 0.07656, saving model to ./baseline_overfit/baseline_overfit.h5\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.0766 - accuracy: 0.9993 - val_loss: 225.5769 - val_accuracy: 0.6194 - lr: 0.0109\n",
      "Epoch 72/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.0799 - accuracy: 0.9993\n",
      "Epoch 72: loss did not improve from 0.07656\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.0799 - accuracy: 0.9993 - val_loss: 225.4305 - val_accuracy: 0.6197 - lr: 0.0107\n",
      "Epoch 73/1000\n",
      "781/782 [============================>.] - ETA: 0s - loss: 0.0769 - accuracy: 0.9993"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-8329565fc458>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m       )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1443\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[0;32m-> 1445\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1446\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1754\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1756\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1757\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mwithout_tracing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m         _frequent_tracing_detector_manager.called_without_tracing(\n\u001b[0m\u001b[1;32m    926\u001b[0m             self._key_for_call_stats)\n\u001b[1;32m    927\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mcalled_without_tracing\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    185\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m       \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m       \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_get_detector\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detectors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FrequentTracingDetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/weakref.py\u001b[0m in \u001b[0;36m__contains__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "      optimizer= keras.optimizers.RMSprop(\n",
    "          learning_rate = 0.045,\n",
    "          momentum=0.9,\n",
    "          rho = 0.9\n",
    "          ),\n",
    "      loss = keras.losses.SparseCategoricalCrossentropy(), \n",
    "      metrics=['accuracy']\n",
    "      )\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks = callbacks,\n",
    "    validation_data = val_ds\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-pkMaxpEun_"
   },
   "source": [
    "## Train plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KlCFLf1TEvnf"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).to_csv(f'./{model_name}/{model_name}.csv', index = False)\n",
    "\n",
    "df = pd.read_csv(f'./{model_name}/{model_name}.csv')\n",
    "\n",
    "df[['val_accuracy', 'accuracy']].plot()\n",
    "df[['val_loss', 'loss']].plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Djgy_kOYEkvb"
   },
   "source": [
    "# Test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rcmfeg5sO2HE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 828s 1s/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_predictions_and_labels(model_path, data):\n",
    "    model = keras.models.load_model(model_path)\n",
    "    predictions = model.predict(data)\n",
    "    labels = []\n",
    "    for _, y in data.as_numpy_iterator():\n",
    "        labels.extend(y)\n",
    "        \n",
    "    return predictions, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, labels = get_predictions_and_labels(f'./{model_name}/{model_name}.h5', val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.01706034120682"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import top_k_accuracy_score\n",
    "print('Top 1 accuracy:', top_k_accuracy_score(labels, predictions, k = 1))\n",
    "print('Top 5 accuracy:', top_k_accuracy_score(labels, predictions, k = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalization_ratio(labels, predictions, MEC):\n",
    "    class_count = Counter(labels)\n",
    "    correct_prediction_count = {i:0 for i in range(1000)}\n",
    "\n",
    "    for p, gt in zip(predictions, labels):\n",
    "        if np.argmax(p) == gt:\n",
    "            correct_prediction_count[gt] += 1\n",
    "\n",
    "    return -sum(correct_prediction_count[key] * log2(class_count[key] / len(labels)) for key in class_count)/MEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20638554550299582"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Generalization ratio:', generalization_ratio(labels, predictions, 1.28e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "a34a21207f2ce0db3116cd2292fdc7281ccb63edb55bd72648ac70c67f93d5eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
